Script started on 2022-11-14 00:53:14-05:00

1. To find the all the retweets that are part of the cluster of authors receiving three or more retweets, I performed the following steps:
a. I began by using grep to filter for retweets in the main tweet file and cutting the fifth column which contains the id of the tweet 
which was being retweeted.
b. Then, I used cut to get the first two columns of the original file, containing the original tweet id and original author. 
c. Next, I joined the retweet_ids file with the all_tweets_author file to map the original author to the retweeted id. 
d. With this data, I then used sort and uniq -c to find the authors who received three or more retweets and stored the list in top_authors
e. Using a for loop, I iterated through this author list and grepped the all_tweets_authors file to get a list of tweets by authors with three
or more retweets, storing the result in filtered_tweets
f. Then, I used grep on the main tweet file and cut the 2nd, 4th, and 5th columns which contain the original author of the retweet, the hashtags 
they used, and the tweet id they retweeted.
g. Using the filtered_tweets file (which contains all the retweets which reference tweets by authors with three or more retweets), 
I iterated through the file and used grep to find all the author and hashtags who retweeted authors with three or more retweets, 
which are matched by retaining the referenced tweet id column (5th column), storing the results in filtered_final_tweets. 
h. With this filtered_final_tweets file, I cut for the second column which contains all the hashtags used by the retweeters to authors
with three or more retweets and converted them to lowercase.
i. Then, I put these hashtags in a list format using tr to separate each hashtag with a new line and sort + uniq to get all the unique
tweets used in this cluster. I stored the result in found_hashtags.tsv. 
j. I used the retweetFrequencies script to iterate through found_hashtags and compute the statistics for each hashtag. See below for the script,
which has a linux command stored inside a variable to compute the frequencies of hashtags in the cluster, the entire dataset, hashtag usage leader,
and relative frequency (relative frequency, frequency hashtags in cluster, frequency overall). I have added the retweetFrequencies script to
the repository.Lastly, I ran the retweetFrequencies.sh script to receive the tabular output and redirected the output to a file which is called retweets_hashtag_freqs.tsv. 
k. Within the script, I have the following variables:
        1. total_hashtags_entire_dataset cuts the hashtags column in the downloaded_tweets_extend_nolf2 file and separates each hashtag to a new line to get a total of all
        hashtags in the dataset.
        2. total_hashtags_in_cluster cuts the hashtags columns in the three_or_more file and separates each hashtag to a new line to get a total of all
        hashtags in the cluster.
        3. leader_user_id, in which I used grep with the current word in $i on the three or more replies subset to get all tweets containing the hashtag and then
        cut to extract all authors who used the hashtag. Then using sort, uniq, and head I printed out the author with the highest occurences.
        4. count_hashtags_entire_dataset, in which I cut the third column of the replies_cleaned file, containing all replies tweets and counted the number of
        occurences of the hashtag by separate each occurence into new lines and using wc to get a count.
        5. count_hashtags_in_cluster, in which I used grep on the three_or_more subset file and counted the number of lines containing the hashtag using wc.
        6. frequency_H_in_C divides count_hashtags_in_cluster and total_hashtags_in_cluster using bc.
        7. frequency_H_overall divides count_hashtags_entire_dataset and total_hashtags_entire_dataset using bc.
        8. relative_frequency_H_C divides frequency_H_in_C and frequency_H_overall using bc.

[sohan@sjsu twitter]$ grep type=retweeted downloaded_tweets_extend_nolf2.tsv | cut -f5 | sed 's/\[<ReferencedTweet id=//g' | sed 's/type=retweeted]//g' | sort > all_retweet_ids.tsv
[sohan@sjsu twitter]$ cut -f1,2 downloaded_tweets_extend_original_nolf2.tsv | sort -k1 > all_tweets_authors.tsv
[sohan@sjsu twitter]$ join -1 1 -2 1 all_retweet_ids.tsv all_tweets_authors.tsv | awk '{print $2}' | sort -n | uniq -c | awk '$1>=3{print $2}' > top_authors.tsv
[sohan@sjsu twitter]$ for i in `cat top_authors.tsv`; do grep -E -w "$i" all_tweets_authors.tsv; done | cut -f1 > filtered_tweets.tsv
[sohan@sjsu twitter]$ grep type=retweeted downloaded_tweets_extend_nolf2.tsv | cut -f2,4,5 > required_columns.tsv
[sohan@sjsu twitter]$ for i in `cat filtered_tweets.tsv`; do grep -E -w "$i" required_columns.tsv; done | tr '[:upper:]' '[:lower:]'  > filtered_final_tweets.tsv
[sohan@sjsu twitter]$ cut -f2 filtered_final_tweets.tsv |  sed 's/[""]//g' | tr '[:upper:]' '[:lower:]' | tr , '\n' | sort | uniq > found_hashtags.tsv
[sohan@sjsu twitter]$ cat retweetFrequencies.sh
#!/bin/bash
echo hashtag_H, cluster_C_leader_user_id, relative_frequency_H_C, frequency_H_in_C, frequency_H_overall, count_H_in_C, count_tweets_in_C, count_H_entire_dataset, count_tweets_entire_dataset
total_hashtags_entire_dataset=$(grep type=retweeted downloaded_tweets_extend_nolf2.tsv | cut -f4 | sed 's/[""]//g' | tr '[:upper:]' '[:lower:]' | tr , '\n' |  wc | awk '{print $1}')
total_hashtags_in_cluster=$(cut -f2 filtered_final_tweets.tsv |  sed 's/[""]//g' | tr '[:upper:]' '[:lower:]' | tr , '\n' | sort | wc | awk '{print $1}')
for i in `cat found_hashtags.tsv`
do
        leader_user_id=$(grep -E -w "$i" filtered_final_tweets.tsv | cut -f1 | sort | uniq -c | sort -nr | head -1 | awk '{print $2}')
        count_hashtags_entire_dataset=$(grep type=retweeted downloaded_tweets_extend_nolf2.tsv | cut -f4  | tr '[:upper:]' '[:lower:]'| grep -E -w "$i" | wc | awk '{print $1}')
        count_hashtags_in_cluster=$(grep -E -w "$i" filtered_final_tweets.tsv | wc | awk '{print $1}')
        frequency_H_in_C=$(echo $count_hashtags_in_cluster / $total_hashtags_in_cluster | bc -l)
        frequency_H_overall=$(echo $count_hashtags_entire_dataset / $total_hashtags_entire_dataset | bc -l)
        relative_frequency_H_C=$(echo $frequency_H_in_C / $frequency_H_overall | bc -l)


        echo $i, $leader_user_id, $relative_frequency_H_C, $frequency_H_in_C, $frequency_H_overall, $count_hashtags_in_cluster, $total_hashtags_in_cluster, $count_hashtags_entire_dataset, $total_hashtags_entire_dataset

done

[sohan@sjsu twitter]$ . retweetFrequencies.sh > retweets_hashtag_freqs.csv
[sohan@sjsu twitter]$ sed 's/,/\t/g' retweets_hashtag_freqs.csv | column -t > retweets_hashtag_freqs.tsv

2. To find the all the replies that are part of the cluster of authors receiving three or more replies, I performed the following steps:
a. I began by using grep to filter for replies in the original file, removing bots, and cutting for the 1st, 2nd, 4th, and 6th columns
which contain the tweet id, author, hashtags, and replied to individual. I stored the results in replies_cleaned. 
b. Then, I cut the 4th column which contains the "replied_to" author id and used sort and uniq to get the authors who received three or
more replies. I stored the result in authors_three_or_more_replies. 
c. Using a for loop, I iterated through the authors_three_or_more_replies file and used awk to find all lines that matched the author
id within the cleaned_replies file, which contains all the replies with bots removed. I stored the result in three_or_more.tsv. 
d. Next, I used cut to get all the hashtags in the three_or_more.tsv file containing only replies for authors with three or more replies
and separate each hashtag on a different line, as well as using sort and uniq to get a list of all hashtags found, with result being stored
in hashtags_for_replies_full.tsv. 
e. I used the repliesFrequencies script to iterate through hashtags_for_replies_full and compute the statistics for each hashtag in the replies. 
See below for the script,which has a linux command stored inside a variable to compute the frequencies of hashtags in the cluster, the entire dataset, 
hashtag usage leader,and relative frequency (relative frequency, frequency hashtags in cluster, frequency overall). I have added the repliesFrequencies 
script to the repository.
Within the script, I have the following variables:
	1. total_hashtags_entire_dataset cuts the hashtags column in the replies_cleaned file and separates each hashtag to a new line to get a total of all
	hashtags in the dataset.
	2. total_hashtags_in_cluster cuts the hashtags columns in the three_or_more file and separates each hashtag to a new line to get a total of all
	hashtags in the cluster. 
	3. leader_user_id, in which I used grep with the current word in $i on the three or more replies subset to get all tweets containing the hashtag and then
	cut to extract all authors who used the hashtag. Then using sort, uniq, and head I printed out the author with the highest occurences. 
	4. count_hashtags_entire_dataset, in which I cut the third column of the replies_cleaned file, containing all replies tweets and counted the number of
	occurences of the hashtag by separate each occurence into new lines and using wc to get a count. 
	5. count_hashtags_in_cluster, in which I used grep on the three_or_more subset file and counted the number of lines containing the hashtag using wc. 
	6. frequency_H_in_C divides count_hashtags_in_cluster and total_hashtags_in_cluster using bc. 
	7. frequency_H_overall divides count_hashtags_entire_dataset and total_hashtags_entire_dataset using bc.
	8. relative_frequency_H_C divides frequency_H_in_C and frequency_H_overall using bc. 
[sohan@sjsu twitter]$ grep type=replied_to downloaded_tweets_extend_original_nolf2.tsv | cut -f1,2,4,6 | awk '$2!=$4{print $0}' | tr '[:upper:]' '[:lower:]' >  replies_cleaned.tsv 
[sohan@sjsu twitter]$ cut -f4 replies_cleaned.tsv | sort -n | uniq -c  | awk '$1>=3{print $2}' > authors_three_or_more_replies.tsv
[sohan@sjsu twitter]$ for i in `cat authors_three_or_more_replies.tsv`; do awk -v word=$i 'word==$4{print $0}' replies_cleaned.tsv | tr '[:upper:]' '[:lower:]'; done > three_or_more.tsv
[sohan@sjsu twitter]$ cut -f3 three_or_more.tsv |  sed 's/[""]//g' | tr '[:upper:]' '[:lower:]' | tr , '\n' | sort | uniq > hashtags_for_replies_full.tsv
[sohan@sjsu twitter]$ cat repliesFrequencies.sh
#!/bin/bash
echo hashtag_H, cluster_C_leader_user_id, relative_frequency_H_C, frequency_H_in_C, frequency_H_overall, count_H_in_C, count_tweets_in_C, count_H_entire_dataset, count_tweets_entire_dataset

total_hashtags_entire_dataset=$(cut -f3 replies_cleaned.tsv | sed 's/[""]//g'| tr , '\n' | wc |  awk '{print $1}')
total_hashtags_in_cluster=$(cut -f3 three_or_more.tsv |  sed 's/[""]//g' | tr '[:upper:]' '[:lower:]' | tr , '\n' | sort | wc | awk '{print $1}')

for i in `cat hashtags_for_replies_full.tsv`
do
	leader_user_id=$(grep -E -w "$i" three_or_more.tsv | cut -f1 | sort | uniq -c | sort -nr | head -1 | awk '{print $2}')
	count_hashtags_entire_dataset=$(cut -f3 replies_cleaned.tsv | tr , '\n' | grep -E -w "$i" | wc | awk '{print $1}')
	count_hashtags_in_cluster=$(grep -E -w "$i" three_or_more.tsv | wc | awk '{print $1}')
	frequency_H_in_C=$(echo $count_hashtags_in_cluster / $total_hashtags_in_cluster | bc -l)
	frequency_H_overall=$(echo $count_hashtags_entire_dataset / $total_hashtags_entire_dataset | bc -l)
	relative_frequency_H_C=$(echo $frequency_H_in_C / $frequency_H_overall | bc -l)
	


	 echo $i, $leader_user_id, $relative_frequency_H_C, $frequency_H_in_C, $frequency_H_overall, $count_hashtags_in_cluster, $total_hashtags_in_cluster, $count_hashtags_entire_dataset, $total_hashtags_entire_dataset

done
[sohan@sjsu twitter]$ . repliesFrequencies.sh > replies_hashtag_freqs.csv
[sohan@sjsu twitter]$  sed 's/,/\t/g' replies_hashtag_freqs.csv | column -t > replies_hashtag_freqs.tsv


3. To find which hashtags were found disproportionally in the retweets file, I used the tables produced for 
retweets and replies above (in csv format). I sorted the third column containing the relative frequency of each hashtag 
in reverse and got the highest relative frequnecies at the top. I then used head to get the highest 30
outputs. I noticed in the retweets file that many of the hashtags occurred 4 times in the cluster and in 
the entire set of retweets (examples: ukrainianrefugees, ukrainewillwin, ห้อง609q5, 戦争反対). Since the occurences
are equal to each other, the relative frequency is higher.

Similarly, for the replies dataset (see below retweets), I sorted the third column containing the relative 
frequency of each hashtag in reverse and got the highest relative frequnecies at the top.
I noticed that there were many s ingle occurences of hashtags in the cluster, as well as the replies file.
(Examples: writingcommunity, wokingham, weath, wato). Since the occurences are equal to each other, 
the relative frequency is higher.


[sohan@sjsu twitter]$ sort -t, -k3 -n -r retweets_hashtag_freqs.csv | head -30
戦争反対, 45379403, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
ウクライナに平和を, 45379403, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
ไอกะทิยู, 1261203450022359043, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
ห้อง609q5, 177400353, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
สู้ไปด้วยกันนะเปี๊ยก, 177400353, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
บ้านอิ่มสุขxฟลุ้ค, 177400353, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
เจ้าเเก้มก้อน, 177400353, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
Противійни, 45379403, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
wichitaks, 1060440219097423872, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
weatherreport, 29447428, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
waronwomen, 29188599, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
wagner, 2800413166, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
vladimirov, 1373739644, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
vereshchagin, 1373739644, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
vasilyvereshchagin, 1373739644, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
urbanwarfare, 1028022611324747776, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
untruth, 4213849704, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
ukrainianrefugees, 45379403, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
ukrainewillwin, 870244616003403781, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
ukrainekrieg, 45379403, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
tuleelk, 2530758806, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
true, 1387010761994682371, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
terrorists, 4213849704, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
teamclots, 139109800, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
susuuuuuu, 4757894056, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
sundaythoughts, 244954523, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
strike, 45379403, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
standagainstfascism, 1028022611324747776, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066
stainedglrrrrrr, 2332033299, 1.49282772333475374232, .00009468352033328599, .00006342561760695144, 4, 42246, 4, 63066

[sohan@sjsu twitter]$ sort -t, -k3 -n -r replies_hashtag_freqs.csv | head -30
Яepublicantraitors, 1496688801393033222, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
zachlavine, 1479156111701950465, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
yourcrosstobear, 1497937514325233669, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
yeg, 1516945309603033088, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
writingcommunity, 1504885460585304072, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
worsegovtever, 1518576153832804352, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
worldsworsttreasuer, 1487534807122726912, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
wokingham, 1511731475376451585, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
witch, 1504885460585304072, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
whereisdougford, 1491054354698104832, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
wethenorth, 1479157876614651907, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
welshnationalchart, 1484303287264628737, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
wealth, 1490349598837202945, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
wato, 1514531201683443717, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
water, 1518576153832804352, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
warning, 1513578377235644416, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
warfare, 1488680757795045376, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
warcrimes, 1515732394996903939, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
wapol, 1513530921475272707, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
wa, 1484676465098895361, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
votingrightsnow, 1481680589304451075, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
votersuppression, 1482391203270344707, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
votemtgout, 1519507151357624321, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
votelabor, 1509016490896683008, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
viruses, 1481754751570268164, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
veryconfused, 1480146015416205317, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
vaxzevria, 1513997146642657283, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
valnotmarco, 1498718697699094537, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
valeriethompson, 1513977674066239498, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
vaccinate, 1491750180986753024, 3.57090909090909099664, .00090909090909090909, .00025458248472505091, 1, 1100, 1, 3928
[sohan@sjsu twitter]$ exit

Script done on 2022-11-14 01:11:57-05:00
